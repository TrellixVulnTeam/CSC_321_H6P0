zhan1767@b2240-06:~/CSC_321/assignment/a4-code-v2-updated$ MKL_NUM_THREADS=1 python cycle_gan.py --use_cycle_consistency_loss
================================================================================
                                      Opts
--------------------------------------------------------------------------------
                           sample_every: 100
                            train_iters: 600
                         checkpoint_dir: checkpoints_cyclegan
                             sample_dir: samples_cyclegan_cycle
                       checkpoint_every: 800
                             batch_size: 16
                             g_conv_dim: 32
                                      Y: Windows
                                     lr: 0.0003
                                  beta2: 0.999
                                  beta1: 0.5
                             image_size: 32
                                      X: Apple
                               log_step: 10
                             d_conv_dim: 32
             use_cycle_consistency_loss: 1
================================================================================
                 G_XtoY
---------------------------------------
CycleGenerator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (resnet_block): ResnetBlock(
    (conv_layer): Sequential(
      (0): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (deconv1): Sequential(
    (0): ConvTranspose2d (64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (deconv2): Sequential(
    (0): ConvTranspose2d (32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  )
)
---------------------------------------
                 G_YtoX
---------------------------------------
CycleGenerator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (resnet_block): ResnetBlock(
    (conv_layer): Sequential(
      (0): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (deconv1): Sequential(
    (0): ConvTranspose2d (64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (deconv2): Sequential(
    (0): ConvTranspose2d (32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  )
)
---------------------------------------
                  D_X
---------------------------------------
DCDiscriminator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv3): Sequential(
    (0): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv4): Sequential(
    (0): Conv2d (128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
  )
)
---------------------------------------
                  D_Y
---------------------------------------
DCDiscriminator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv3): Sequential(
    (0): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv4): Sequential(
    (0): Conv2d (128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
  )
)
---------------------------------------
Models moved to GPU.
Iteration [   10/  600] | d_real_loss: 0.2762 | d_Y_loss: 0.1547 | d_X_loss: 0.2362 | d_fake_loss: 0.3908 | g_loss: 0.6938
Iteration [   20/  600] | d_real_loss: 0.3371 | d_Y_loss: 0.1813 | d_X_loss: 0.1927 | d_fake_loss: 0.3739 | g_loss: 0.6928
Iteration [   30/  600] | d_real_loss: 0.2526 | d_Y_loss: 0.1597 | d_X_loss: 0.1601 | d_fake_loss: 0.3198 | g_loss: 0.7444
Iteration [   40/  600] | d_real_loss: 0.2905 | d_Y_loss: 0.1400 | d_X_loss: 0.1650 | d_fake_loss: 0.3050 | g_loss: 0.7543
Iteration [   50/  600] | d_real_loss: 0.2765 | d_Y_loss: 0.1515 | d_X_loss: 0.1782 | d_fake_loss: 0.3297 | g_loss: 0.7061
Iteration [   60/  600] | d_real_loss: 0.3322 | d_Y_loss: 0.1174 | d_X_loss: 0.1575 | d_fake_loss: 0.2748 | g_loss: 0.7756
Iteration [   70/  600] | d_real_loss: 0.4157 | d_Y_loss: 0.1716 | d_X_loss: 0.1935 | d_fake_loss: 0.3651 | g_loss: 0.8446
Iteration [   80/  600] | d_real_loss: 0.4019 | d_Y_loss: 0.1955 | d_X_loss: 0.1580 | d_fake_loss: 0.3536 | g_loss: 0.7427
Iteration [   90/  600] | d_real_loss: 0.3713 | d_Y_loss: 0.2147 | d_X_loss: 0.2083 | d_fake_loss: 0.4230 | g_loss: 0.8477
Iteration [  100/  600] | d_real_loss: 0.4081 | d_Y_loss: 0.1410 | d_X_loss: 0.2101 | d_fake_loss: 0.3511 | g_loss: 0.7049
Saved samples_cyclegan_cycle/sample-000100-X-Y.png
Saved samples_cyclegan_cycle/sample-000100-Y-X.png
Iteration [  110/  600] | d_real_loss: 0.3408 | d_Y_loss: 0.1167 | d_X_loss: 0.1467 | d_fake_loss: 0.2633 | g_loss: 0.7978
Iteration [  120/  600] | d_real_loss: 0.2617 | d_Y_loss: 0.1176 | d_X_loss: 0.1658 | d_fake_loss: 0.2835 | g_loss: 0.8336
Iteration [  130/  600] | d_real_loss: 0.3505 | d_Y_loss: 0.1710 | d_X_loss: 0.1619 | d_fake_loss: 0.3329 | g_loss: 0.8190
Iteration [  140/  600] | d_real_loss: 0.3538 | d_Y_loss: 0.1549 | d_X_loss: 0.1183 | d_fake_loss: 0.2732 | g_loss: 0.8277
Iteration [  150/  600] | d_real_loss: 0.3291 | d_Y_loss: 0.1169 | d_X_loss: 0.1974 | d_fake_loss: 0.3143 | g_loss: 0.9240
Iteration [  160/  600] | d_real_loss: 0.4275 | d_Y_loss: 0.1514 | d_X_loss: 0.1701 | d_fake_loss: 0.3216 | g_loss: 0.9109
Iteration [  170/  600] | d_real_loss: 0.4043 | d_Y_loss: 0.1052 | d_X_loss: 0.2548 | d_fake_loss: 0.3600 | g_loss: 0.7825
Iteration [  180/  600] | d_real_loss: 0.4061 | d_Y_loss: 0.1001 | d_X_loss: 0.1694 | d_fake_loss: 0.2694 | g_loss: 0.8683
Iteration [  190/  600] | d_real_loss: 0.3737 | d_Y_loss: 0.1684 | d_X_loss: 0.1463 | d_fake_loss: 0.3146 | g_loss: 0.8809
Iteration [  200/  600] | d_real_loss: 0.3480 | d_Y_loss: 0.1380 | d_X_loss: 0.1728 | d_fake_loss: 0.3107 | g_loss: 0.9473
Saved samples_cyclegan_cycle/sample-000200-X-Y.png
Saved samples_cyclegan_cycle/sample-000200-Y-X.png
Iteration [  210/  600] | d_real_loss: 0.3521 | d_Y_loss: 0.1502 | d_X_loss: 0.1657 | d_fake_loss: 0.3159 | g_loss: 0.7201
Iteration [  220/  600] | d_real_loss: 0.3113 | d_Y_loss: 0.0538 | d_X_loss: 0.1654 | d_fake_loss: 0.2193 | g_loss: 0.8627
Iteration [  230/  600] | d_real_loss: 0.3522 | d_Y_loss: 0.0861 | d_X_loss: 0.1985 | d_fake_loss: 0.2846 | g_loss: 0.8594
Iteration [  240/  600] | d_real_loss: 0.3670 | d_Y_loss: 0.1507 | d_X_loss: 0.2011 | d_fake_loss: 0.3518 | g_loss: 0.9329
Iteration [  250/  600] | d_real_loss: 0.2653 | d_Y_loss: 0.1345 | d_X_loss: 0.2083 | d_fake_loss: 0.3428 | g_loss: 1.0709
Iteration [  260/  600] | d_real_loss: 0.3602 | d_Y_loss: 0.1382 | d_X_loss: 0.2975 | d_fake_loss: 0.4357 | g_loss: 0.8521
Iteration [  270/  600] | d_real_loss: 0.3848 | d_Y_loss: 0.1323 | d_X_loss: 0.1893 | d_fake_loss: 0.3215 | g_loss: 0.9278
Iteration [  280/  600] | d_real_loss: 0.3156 | d_Y_loss: 0.1981 | d_X_loss: 0.2066 | d_fake_loss: 0.4047 | g_loss: 0.8326
Iteration [  290/  600] | d_real_loss: 0.3699 | d_Y_loss: 0.1747 | d_X_loss: 0.2238 | d_fake_loss: 0.3985 | g_loss: 0.8700
Iteration [  300/  600] | d_real_loss: 0.2397 | d_Y_loss: 0.1183 | d_X_loss: 0.1466 | d_fake_loss: 0.2649 | g_loss: 0.9646
Saved samples_cyclegan_cycle/sample-000300-X-Y.png
Saved samples_cyclegan_cycle/sample-000300-Y-X.png
Iteration [  310/  600] | d_real_loss: 0.4834 | d_Y_loss: 0.1709 | d_X_loss: 0.2443 | d_fake_loss: 0.4152 | g_loss: 0.8332
Iteration [  320/  600] | d_real_loss: 0.2861 | d_Y_loss: 0.1727 | d_X_loss: 0.1958 | d_fake_loss: 0.3685 | g_loss: 0.8832
Iteration [  330/  600] | d_real_loss: 0.3196 | d_Y_loss: 0.1582 | d_X_loss: 0.2769 | d_fake_loss: 0.4351 | g_loss: 0.8688
Iteration [  340/  600] | d_real_loss: 0.3217 | d_Y_loss: 0.1571 | d_X_loss: 0.1580 | d_fake_loss: 0.3151 | g_loss: 0.8773
Iteration [  350/  600] | d_real_loss: 0.4313 | d_Y_loss: 0.1401 | d_X_loss: 0.1898 | d_fake_loss: 0.3299 | g_loss: 0.8126
Iteration [  360/  600] | d_real_loss: 0.4672 | d_Y_loss: 0.1670 | d_X_loss: 0.2021 | d_fake_loss: 0.3690 | g_loss: 0.8548
Iteration [  370/  600] | d_real_loss: 0.3852 | d_Y_loss: 0.2161 | d_X_loss: 0.2071 | d_fake_loss: 0.4232 | g_loss: 0.9153
Iteration [  380/  600] | d_real_loss: 0.3969 | d_Y_loss: 0.1267 | d_X_loss: 0.2030 | d_fake_loss: 0.3297 | g_loss: 0.8636
Iteration [  390/  600] | d_real_loss: 0.2626 | d_Y_loss: 0.1550 | d_X_loss: 0.1661 | d_fake_loss: 0.3211 | g_loss: 0.8692
Iteration [  400/  600] | d_real_loss: 0.3203 | d_Y_loss: 0.1610 | d_X_loss: 0.1371 | d_fake_loss: 0.2981 | g_loss: 0.8018
Saved samples_cyclegan_cycle/sample-000400-X-Y.png
Saved samples_cyclegan_cycle/sample-000400-Y-X.png
Iteration [  410/  600] | d_real_loss: 0.5242 | d_Y_loss: 0.1038 | d_X_loss: 0.1726 | d_fake_loss: 0.2764 | g_loss: 0.8012
Iteration [  420/  600] | d_real_loss: 0.2908 | d_Y_loss: 0.1566 | d_X_loss: 0.1804 | d_fake_loss: 0.3371 | g_loss: 0.9009
Iteration [  430/  600] | d_real_loss: 0.3831 | d_Y_loss: 0.1758 | d_X_loss: 0.2023 | d_fake_loss: 0.3781 | g_loss: 0.9203
Iteration [  440/  600] | d_real_loss: 0.3602 | d_Y_loss: 0.1256 | d_X_loss: 0.1692 | d_fake_loss: 0.2949 | g_loss: 0.8779
Iteration [  450/  600] | d_real_loss: 0.4168 | d_Y_loss: 0.1099 | d_X_loss: 0.2162 | d_fake_loss: 0.3261 | g_loss: 0.9508
Iteration [  460/  600] | d_real_loss: 0.4016 | d_Y_loss: 0.1074 | d_X_loss: 0.2188 | d_fake_loss: 0.3262 | g_loss: 0.8960
Iteration [  470/  600] | d_real_loss: 0.2239 | d_Y_loss: 0.0749 | d_X_loss: 0.1382 | d_fake_loss: 0.2131 | g_loss: 0.9488
Iteration [  480/  600] | d_real_loss: 0.3010 | d_Y_loss: 0.1706 | d_X_loss: 0.1393 | d_fake_loss: 0.3098 | g_loss: 0.8327
Iteration [  490/  600] | d_real_loss: 0.2891 | d_Y_loss: 0.1495 | d_X_loss: 0.2029 | d_fake_loss: 0.3524 | g_loss: 0.9343
Iteration [  500/  600] | d_real_loss: 0.4154 | d_Y_loss: 0.1239 | d_X_loss: 0.2155 | d_fake_loss: 0.3394 | g_loss: 0.9205
Saved samples_cyclegan_cycle/sample-000500-X-Y.png
Saved samples_cyclegan_cycle/sample-000500-Y-X.png
Iteration [  510/  600] | d_real_loss: 0.3328 | d_Y_loss: 0.1050 | d_X_loss: 0.1483 | d_fake_loss: 0.2533 | g_loss: 0.9869
Iteration [  520/  600] | d_real_loss: 0.3134 | d_Y_loss: 0.1479 | d_X_loss: 0.1335 | d_fake_loss: 0.2814 | g_loss: 0.9653
Iteration [  530/  600] | d_real_loss: 0.4687 | d_Y_loss: 0.1596 | d_X_loss: 0.1117 | d_fake_loss: 0.2712 | g_loss: 0.8875
Iteration [  540/  600] | d_real_loss: 0.3527 | d_Y_loss: 0.1477 | d_X_loss: 0.1773 | d_fake_loss: 0.3250 | g_loss: 0.8767
Iteration [  550/  600] | d_real_loss: 0.2591 | d_Y_loss: 0.0970 | d_X_loss: 0.1899 | d_fake_loss: 0.2869 | g_loss: 0.8986
Iteration [  560/  600] | d_real_loss: 0.2818 | d_Y_loss: 0.1735 | d_X_loss: 0.1687 | d_fake_loss: 0.3422 | g_loss: 0.9336
Iteration [  570/  600] | d_real_loss: 0.2553 | d_Y_loss: 0.1680 | d_X_loss: 0.2095 | d_fake_loss: 0.3775 | g_loss: 0.9880
Iteration [  580/  600] | d_real_loss: 0.2574 | d_Y_loss: 0.1112 | d_X_loss: 0.1267 | d_fake_loss: 0.2380 | g_loss: 0.9481
Iteration [  590/  600] | d_real_loss: 0.3242 | d_Y_loss: 0.1693 | d_X_loss: 0.2041 | d_fake_loss: 0.3734 | g_loss: 0.9073
Iteration [  600/  600] | d_real_loss: 0.3543 | d_Y_loss: 0.1010 | d_X_loss: 0.1705 | d_fake_loss: 0.2715 | g_loss: 0.8942
Saved samples_cyclegan_cycle/sample-000600-X-Y.png
Saved samples_cyclegan_cycle/sample-000600-Y-X.png
