zhan1767@b2240-03:~/CSC_321/assignment/a4-code-v2-updated$ MKL_NUM_THREADS=1 python cycle_gan.py --use_cycle_consistency_loss
================================================================================
                                      Opts
--------------------------------------------------------------------------------
                           sample_every: 100
                            train_iters: 600
                         checkpoint_dir: checkpoints_cyclegan
                             sample_dir: samples_cyclegan_cycle
                       checkpoint_every: 800
                             batch_size: 16
                             g_conv_dim: 32
                                      Y: Windows
                                     lr: 0.0003
                                  beta2: 0.999
                                  beta1: 0.5
                             image_size: 32
                                      X: Apple
                               log_step: 10
                             d_conv_dim: 32
             use_cycle_consistency_loss: 1
================================================================================
                 G_XtoY
---------------------------------------
CycleGenerator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (resnet_block): ResnetBlock(
    (conv_layer): Sequential(
      (0): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (deconv1): Sequential(
    (0): ConvTranspose2d (64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (deconv2): Sequential(
    (0): ConvTranspose2d (32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  )
)
---------------------------------------
                 G_YtoX
---------------------------------------
CycleGenerator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (resnet_block): ResnetBlock(
    (conv_layer): Sequential(
      (0): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (deconv1): Sequential(
    (0): ConvTranspose2d (64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (deconv2): Sequential(
    (0): ConvTranspose2d (32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  )
)
---------------------------------------
                  D_X
---------------------------------------
DCDiscriminator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv3): Sequential(
    (0): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv4): Sequential(
    (0): Conv2d (128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
  )
)
---------------------------------------
                  D_Y
---------------------------------------
DCDiscriminator(
  (conv1): Sequential(
    (0): Conv2d (3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv2): Sequential(
    (0): Conv2d (32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv3): Sequential(
    (0): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
  )
  (conv4): Sequential(
    (0): Conv2d (128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
  )
)
---------------------------------------
Models moved to GPU.
Iteration [   10/  600] | d_real_loss: 0.1755 | d_Y_loss: 0.0578 | d_X_loss: 0.0725 | d_fake_loss: 0.1303 | g_loss: 686.7182
Iteration [   20/  600] | d_real_loss: 0.0924 | d_Y_loss: 0.0251 | d_X_loss: 0.0495 | d_fake_loss: 0.0747 | g_loss: 442.8125
Iteration [   30/  600] | d_real_loss: 0.0284 | d_Y_loss: 0.0089 | d_X_loss: 0.0122 | d_fake_loss: 0.0211 | g_loss: 321.9594
Iteration [   40/  600] | d_real_loss: 0.0219 | d_Y_loss: 0.0046 | d_X_loss: 0.0116 | d_fake_loss: 0.0162 | g_loss: 316.7308
Iteration [   50/  600] | d_real_loss: 0.0090 | d_Y_loss: 0.0044 | d_X_loss: 0.0032 | d_fake_loss: 0.0075 | g_loss: 239.3962
Iteration [   60/  600] | d_real_loss: 0.0158 | d_Y_loss: 0.0045 | d_X_loss: 0.0533 | d_fake_loss: 0.0579 | g_loss: 192.4130
Iteration [   70/  600] | d_real_loss: 0.0042 | d_Y_loss: 0.0014 | d_X_loss: 0.0019 | d_fake_loss: 0.0033 | g_loss: 232.1578
Iteration [   80/  600] | d_real_loss: 0.0099 | d_Y_loss: 0.0020 | d_X_loss: 0.0093 | d_fake_loss: 0.0113 | g_loss: 174.5205
Iteration [   90/  600] | d_real_loss: 0.0043 | d_Y_loss: 0.0015 | d_X_loss: 0.0048 | d_fake_loss: 0.0063 | g_loss: 186.1969
Iteration [  100/  600] | d_real_loss: 0.0035 | d_Y_loss: 0.0010 | d_X_loss: 0.0025 | d_fake_loss: 0.0036 | g_loss: 156.1225
Saved samples_cyclegan_cycle/sample-000100-X-Y.png
Saved samples_cyclegan_cycle/sample-000100-Y-X.png
Iteration [  110/  600] | d_real_loss: 0.0025 | d_Y_loss: 0.0011 | d_X_loss: 0.0008 | d_fake_loss: 0.0018 | g_loss: 130.7439
Iteration [  120/  600] | d_real_loss: 0.0013 | d_Y_loss: 0.0003 | d_X_loss: 0.0010 | d_fake_loss: 0.0013 | g_loss: 113.6378
Iteration [  130/  600] | d_real_loss: 0.0023 | d_Y_loss: 0.0008 | d_X_loss: 0.0017 | d_fake_loss: 0.0025 | g_loss: 118.6435
Iteration [  140/  600] | d_real_loss: 0.0049 | d_Y_loss: 0.0009 | d_X_loss: 0.0007 | d_fake_loss: 0.0016 | g_loss: 164.7016
Iteration [  150/  600] | d_real_loss: 0.0024 | d_Y_loss: 0.0009 | d_X_loss: 0.0005 | d_fake_loss: 0.0014 | g_loss: 138.9644
Iteration [  160/  600] | d_real_loss: 0.0009 | d_Y_loss: 0.0014 | d_X_loss: 0.0003 | d_fake_loss: 0.0016 | g_loss: 154.1638
Iteration [  170/  600] | d_real_loss: 0.0011 | d_Y_loss: 0.0014 | d_X_loss: 0.0003 | d_fake_loss: 0.0017 | g_loss: 112.6396
Iteration [  180/  600] | d_real_loss: 0.0020 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 166.0374
Iteration [  190/  600] | d_real_loss: 0.0023 | d_Y_loss: 0.0005 | d_X_loss: 0.0007 | d_fake_loss: 0.0012 | g_loss: 141.8322
Iteration [  200/  600] | d_real_loss: 0.0025 | d_Y_loss: 0.0001 | d_X_loss: 0.0011 | d_fake_loss: 0.0012 | g_loss: 99.3097
Saved samples_cyclegan_cycle/sample-000200-X-Y.png
Saved samples_cyclegan_cycle/sample-000200-Y-X.png
Iteration [  210/  600] | d_real_loss: 0.0015 | d_Y_loss: 0.0007 | d_X_loss: 0.0006 | d_fake_loss: 0.0013 | g_loss: 149.1019
Iteration [  220/  600] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0004 | d_fake_loss: 0.0005 | g_loss: 76.0143
Iteration [  230/  600] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 92.5703
Iteration [  240/  600] | d_real_loss: 0.0007 | d_Y_loss: 0.0026 | d_X_loss: 0.0002 | d_fake_loss: 0.0028 | g_loss: 94.4133
Iteration [  250/  600] | d_real_loss: 0.0003 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 92.3498
Iteration [  260/  600] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0004 | g_loss: 92.9218
Iteration [  270/  600] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 89.0295
Iteration [  280/  600] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 78.5504
Iteration [  290/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0003 | d_X_loss: 0.0000 | d_fake_loss: 0.0003 | g_loss: 89.9468
Iteration [  300/  600] | d_real_loss: 0.0003 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 116.9831
Saved samples_cyclegan_cycle/sample-000300-X-Y.png
Saved samples_cyclegan_cycle/sample-000300-Y-X.png
Iteration [  310/  600] | d_real_loss: 0.0007 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 105.8134
Iteration [  320/  600] | d_real_loss: 0.0005 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 68.3207
Iteration [  330/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 88.9803
Iteration [  340/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 65.8180
Iteration [  350/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 121.9171
Iteration [  360/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 113.6616
Iteration [  370/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 84.1794
Iteration [  380/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 78.0686
Iteration [  390/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 86.4529
Iteration [  400/  600] | d_real_loss: 0.0032 | d_Y_loss: 0.0005 | d_X_loss: 0.0003 | d_fake_loss: 0.0007 | g_loss: 68.9000
Saved samples_cyclegan_cycle/sample-000400-X-Y.png
Saved samples_cyclegan_cycle/sample-000400-Y-X.png
Iteration [  410/  600] | d_real_loss: 0.0034 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 68.5608
Iteration [  420/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 62.8009
Iteration [  430/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 66.7056
Iteration [  440/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 64.7032
Iteration [  450/  600] | d_real_loss: 0.0004 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 64.9865
Iteration [  460/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0007 | d_X_loss: 0.0001 | d_fake_loss: 0.0008 | g_loss: 89.2084
Iteration [  470/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 108.6817
Iteration [  480/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0002 | d_fake_loss: 0.0002 | g_loss: 72.8033
Iteration [  490/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 60.2441
Iteration [  500/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0003 | d_fake_loss: 0.0003 | g_loss: 56.9948
Saved samples_cyclegan_cycle/sample-000500-X-Y.png
Saved samples_cyclegan_cycle/sample-000500-Y-X.png
Iteration [  510/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 66.7353
Iteration [  520/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 64.1723
Iteration [  530/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 72.3202
Iteration [  540/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 60.1153
Iteration [  550/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 66.6570
Iteration [  560/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0002 | g_loss: 77.3370
Iteration [  570/  600] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 68.7776
Iteration [  580/  600] | d_real_loss: 0.0001 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 61.3104
Iteration [  590/  600] | d_real_loss: 0.0000 | d_Y_loss: 0.0001 | d_X_loss: 0.0000 | d_fake_loss: 0.0001 | g_loss: 93.3022
Iteration [  600/  600] | d_real_loss: 0.0002 | d_Y_loss: 0.0000 | d_X_loss: 0.0000 | d_fake_loss: 0.0000 | g_loss: 81.3404
Saved samples_cyclegan_cycle/sample-000600-X-Y.png
Saved samples_cyclegan_cycle/sample-000600-Y-X.png
